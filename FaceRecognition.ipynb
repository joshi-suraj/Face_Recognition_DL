{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10Hb4DF3eyOATjOEN5mA7Ft56P1PPVNBb",
      "authorship_tag": "ABX9TyPNMCpwC+5FR73XWhMsJTfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshi-suraj/Face_Recognition_DL/blob/main/FaceRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. SETUP**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nLbacgDHx3T-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Install Dependencies**\n",
        "\n",
        "The below libraries are already installed in colab these are specified if using any other platform like jupyter.\n"
      ],
      "metadata": {
        "id": "fm-4SijryDiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow opencv-python matplotlib"
      ],
      "metadata": {
        "id": "p758wcPkyLND"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Import Dependencies**"
      ],
      "metadata": {
        "id": "Vu-6cK6IyL2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Standard Dependencies\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "DgjbPPuiyRZf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Tensorflow Dependencies - Functional API\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten"
      ],
      "metadata": {
        "id": "4l7kc8teyRsp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Set GPU Growth**\n",
        "\n",
        "Setting up GPU growth or dynamic memory allocation for GPU memory is usually required when you're working with TensorFlow (or other deep learning frameworks) on systems that have a physical GPU, like in personal computers or remote servers.\n",
        "\n",
        "This is not typically necessary when using Google Colab because Colab manages GPU memory allocation automatically. However, if you're working on your local machine or a remote server, you might need to do this to avoid reserving all GPU memory at once, which can lead to inefficient usage.\n",
        "\n",
        "This code iterates through the available GPUs and enables memory growth for each of them. Memory growth means that TensorFlow will only allocate GPU memory as needed, rather than reserving the entire GPU memory from the start."
      ],
      "metadata": {
        "id": "xVc1X2X3ySIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "shXXuxctyZj5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4 Create Folders Structures**"
      ],
      "metadata": {
        "id": "hpbUzEjfyaMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pos_Path = os.path.join('data', 'Positive')\n",
        "Neg_Path = os.path.join('data', 'Negative')\n",
        "Anc_Path = os.path.join('data', 'Anchor')"
      ],
      "metadata": {
        "id": "XAv_nU-WyhTY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(Pos_Path)\n",
        "os.makedirs(Neg_Path)\n",
        "os.makedirs(Anc_Path)"
      ],
      "metadata": {
        "id": "QTB7F9pX8elm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. COLLECTING ANCHOR AND POSITIVE IMAGES**"
      ],
      "metadata": {
        "id": "KcXrHzxACTIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 Getting Labelled Faces in the Wild Dataset**"
      ],
      "metadata": {
        "id": "jRC0OBsWCTwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf lfw.tgz"
      ],
      "metadata": {
        "id": "Osorm_VgCzxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for directory in os.listdir('lfw'):\n",
        "  for file in os.listdir(os.path.join('lfw', directory)):\n",
        "    Ex_Path = os.path.join('lfw',directory,file)\n",
        "    New_Path = os.path.join(Neg_Path,file)\n",
        "    os.replace(Ex_Path,New_Path)"
      ],
      "metadata": {
        "id": "sWpLGlESIn9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for directory in os.listdir('lfw'):\n",
        "  for file in os.listdir(os.path.join('lfw', directory)):\n",
        "    print(os.path.join('lfw',directory,file))\n",
        "    print(os.path.join(Neg_Path,file))\n"
      ],
      "metadata": {
        "id": "lYnqBPu5JW8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import uuid(Universal Unique Identifier) library to generate unique image names\n",
        "import uuid"
      ],
      "metadata": {
        "id": "Q2iTPGdRViLY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Establish a connection to the webcam\n",
        "cap = cv2.VideoCapture(4)\n",
        "while cap.isOpened():\n",
        "  ret, frame=cap.read()\n",
        "\n",
        "  #Collect Anchors\n",
        "  if cv2.waitkey(1) & 0XFF == ord('a'):\n",
        "    #Create the Unique File Path\n",
        "    imgname = os.path.join(Anc_Path, '{}.jpg'.format(uuid.uuid1()))\n",
        "    #Write out Anchor image\n",
        "    cv2.imwrite(imgname, frame)\n",
        "\n",
        "\n",
        "  #Collect Positive\n",
        "  if cv2.waitkey(1) & 0XFF == ord('a'):\n",
        "    #Create the Unique File Path\n",
        "    imgname = os.path.join(Pos_Path, '{}.jpg'.format(uuid.uuid1()))\n",
        "    #Write out Positive image\n",
        "    cv2.imwrite(imgname, frame)\n",
        "\n",
        "  #Show images back to the Screen\n",
        "  cv2.imshow('Suraj Image', frame)\n",
        "\n",
        "  #Breaking Gracefully\n",
        "  if cv2.waitkey(1) & 0XFF == ord('q'):\n",
        "    break\n",
        "\n",
        "#Releasing Webcam\n",
        "cap.release()\n",
        "#close the image show frame\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "IPHVahmwPxla"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. LOAD AND PREPROCESS IMAGE**"
      ],
      "metadata": {
        "id": "_CXvCoLsvzIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1 Get Image Directories**"
      ],
      "metadata": {
        "id": "Jep1_hnDvzZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anchor = tf.data.Dataset.list_files(Anc_Path+'\\*.jpg').take(300)\n",
        "positive = tf.data.Dataset.list_files(Pos_Path+'\\*.jpg').take(300)\n",
        "negative = tf.data.Dataset.list_files(Neg_Path+'\\*.jpg').take(300)"
      ],
      "metadata": {
        "id": "lsU8ShB6wXNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 Preprocessing - Scale and Resize**"
      ],
      "metadata": {
        "id": "7ZAorjp6vzqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path):\n",
        "  #Reading in image from file path\n",
        "  byte_img = tf.io.read_file(file_path)\n",
        "\n",
        "  #Decoding the jpg image\n",
        "  img = tf.io.decode_jpeg(byte_img)\n",
        "\n",
        "  #Resize the image to 100*100 pixel\n",
        "  img = tf.image.resize(img, (100,100))\n",
        "\n",
        "  #rescaling or normalizing the image i.e. Scale image to be between 0 and 1\n",
        "  img = img/255.0\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "RgyzPo1o-3wB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 Create Labelled Dataset**"
      ],
      "metadata": {
        "id": "cU34XxFwvz70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "data = positives.concatenate(negatives)"
      ],
      "metadata": {
        "id": "7U4_uKr--25X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.4 Build Train and Test Partition**"
      ],
      "metadata": {
        "id": "pH-n2k8Sv0b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_twin(input_img, validation_img, label):\n",
        "    return(preprocess(input_img), preprocess(validation_img), label)"
      ],
      "metadata": {
        "id": "faogrjlJXDJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build dataloader pipeline\n",
        "data = data.map(preprocess_twin)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=10000)"
      ],
      "metadata": {
        "id": "xxqI7xW9APNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training partition\n",
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ],
      "metadata": {
        "id": "GQC8GJ_pAPxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing partition\n",
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ],
      "metadata": {
        "id": "t0_O5v25ASUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Model Engineering**"
      ],
      "metadata": {
        "id": "Gw-irx2vHyoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1 Build Embedding Layer**"
      ],
      "metadata": {
        "id": "r5W05qQ4H0rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_embedding():\n",
        "    inp = Input(shape=(100,100,3), name='input_image')\n",
        "\n",
        "    # First block\n",
        "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
        "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
        "\n",
        "    # Second block\n",
        "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
        "\n",
        "    # Third block\n",
        "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
        "\n",
        "    # Final embedding block\n",
        "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
        "    f1 = Flatten()(c4)\n",
        "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
        "\n",
        "\n",
        "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
      ],
      "metadata": {
        "id": "ID5QKiJHH3gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = make_embedding()"
      ],
      "metadata": {
        "id": "FBY3uAUAIAi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.summary()"
      ],
      "metadata": {
        "id": "z8X5vVWLIA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 Build Distance Layer**"
      ],
      "metadata": {
        "id": "Z6JkIY5wIUFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Siamese L1 Distance class\n",
        "class L1Dist(Layer):\n",
        "\n",
        "    # Init method - inheritance\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "    # Magic happens here - similarity calculation\n",
        "    def call(self, input_embedding, validation_embedding):\n",
        "        return tf.math.abs(input_embedding - validation_embedding)"
      ],
      "metadata": {
        "id": "C1SZ4xNCIOUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3 Make Siamese Model**"
      ],
      "metadata": {
        "id": "C8g1B3oJIdtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_siamese_model():\n",
        "\n",
        "    # Anchor image input in the network\n",
        "    input_image = Input(name='input_img', shape=(100,100,3))\n",
        "\n",
        "    # Validation image in the network\n",
        "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
        "\n",
        "    # Combine siamese distance components\n",
        "    siamese_layer = L1Dist()\n",
        "    siamese_layer._name = 'distance'\n",
        "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
        "\n",
        "    # Classification layer\n",
        "    classifier = Dense(1, activation='sigmoid')(distances)\n",
        "\n",
        "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
      ],
      "metadata": {
        "id": "vuzHS9V9IfCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model = make_siamese_model()"
      ],
      "metadata": {
        "id": "Z2nxWiS0Ionk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.summary()"
      ],
      "metadata": {
        "id": "H3Dk7IqyIqtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Training**"
      ],
      "metadata": {
        "id": "mYMg8nYdJLsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.1 Setup Loss and Optimizer**"
      ],
      "metadata": {
        "id": "Ux1b7l8wJL8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cross_loss = tf.losses.BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "UC68jMMrJXLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001"
      ],
      "metadata": {
        "id": "lMYOMCWXJZLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.2 Establish Checkpoints**"
      ],
      "metadata": {
        "id": "9I0dsrOOJMMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
      ],
      "metadata": {
        "id": "0JXXv5s-JdUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.3 Build Train Step Function**"
      ],
      "metadata": {
        "id": "XVR1vYOSJu1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(batch):\n",
        "\n",
        "    # Record all of our operations\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Get anchor and positive/negative image\n",
        "        X = batch[:2]\n",
        "        # Get label\n",
        "        y = batch[2]\n",
        "\n",
        "        # Forward pass\n",
        "        yhat = siamese_model(X, training=True)\n",
        "        # Calculate loss\n",
        "        loss = binary_cross_loss(y, yhat)\n",
        "    print(loss)\n",
        "\n",
        "    # Calculate gradients\n",
        "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
        "\n",
        "    # Calculate updated weights and apply to siamese model\n",
        "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
        "\n",
        "    # Return loss\n",
        "    return loss"
      ],
      "metadata": {
        "id": "5qRF4bgDJpJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.4 Build Training Loop**"
      ],
      "metadata": {
        "id": "JAs4_Tp1JMb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import metric calculations\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ],
      "metadata": {
        "id": "qomD9m0HJ1gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data, EPOCHS):\n",
        "    # Loop through epochs\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
        "        progbar = tf.keras.utils.Progbar(len(data))\n",
        "\n",
        "        # Creating a metric object\n",
        "        r = Recall()\n",
        "        p = Precision()\n",
        "\n",
        "        # Loop through each batch\n",
        "        for idx, batch in enumerate(data):\n",
        "            # Run train step here\n",
        "            loss = train_step(batch)\n",
        "            yhat = siamese_model.predict(batch[:2])\n",
        "            r.update_state(batch[2], yhat)\n",
        "            p.update_state(batch[2], yhat)\n",
        "            progbar.update(idx+1)\n",
        "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
        "\n",
        "        # Save checkpoints\n",
        "        if epoch % 10 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)"
      ],
      "metadata": {
        "id": "GiV0SofnJ11B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.5 Train the model**"
      ],
      "metadata": {
        "id": "gGdsUsOvJMs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50"
      ],
      "metadata": {
        "id": "P3JIkIakJ7uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_data, EPOCHS)"
      ],
      "metadata": {
        "id": "WfuwiapcJ71z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Evaluate Model**"
      ],
      "metadata": {
        "id": "MyACHBe5JPJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.1 Import Metrics**"
      ],
      "metadata": {
        "id": "zWMed7dnJPZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import metric calculations\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ],
      "metadata": {
        "id": "2jOoDZI_KLGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.2 Make Predictions**"
      ],
      "metadata": {
        "id": "TLsbKs74JPpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of test data\n",
        "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "uEFDOABvKLya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = siamese_model.predict([test_input, test_val])"
      ],
      "metadata": {
        "id": "-7C7mkilKTdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Post processing the results\n",
        "[1 if prediction > 0.5 else 0 for prediction in y_hat ]"
      ],
      "metadata": {
        "id": "nWa5fOmAKTfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true"
      ],
      "metadata": {
        "id": "TRQwAKaJKTZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.3 Calculate Metrics**"
      ],
      "metadata": {
        "id": "jkaC8LTgJP-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a metric object\n",
        "m = Recall()\n",
        "\n",
        "# Calculating the recall value\n",
        "m.update_state(y_true, y_hat)\n",
        "\n",
        "# Return Recall Result\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "id": "mz2ddnFMKMZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a metric object\n",
        "m = Precision()\n",
        "\n",
        "# Calculating the recall value\n",
        "m.update_state(y_true, y_hat)\n",
        "\n",
        "# Return Recall Result\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "id": "ivGlp8iHKc6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.4 Viz Results**"
      ],
      "metadata": {
        "id": "OiSN77guJRL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set plot size\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "# Set first subplot\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(test_input[0])\n",
        "\n",
        "# Set second subplot\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(test_val[0])\n",
        "\n",
        "# Renders cleanly\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9JMvlBK8Khxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Save Model**"
      ],
      "metadata": {
        "id": "Gi1EdP7rJRdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save weights\n",
        "siamese_model.save('siamesemodelv2.h5')"
      ],
      "metadata": {
        "id": "6QKLuiybKmFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model\n",
        "siamese_model = tf.keras.models.load_model('siamesemodelv2.h5',\n",
        "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
      ],
      "metadata": {
        "id": "WS-2xYv1KmLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with reloaded model\n",
        "siamese_model.predict([test_input, test_val])"
      ],
      "metadata": {
        "id": "NuVcZ3LbKmRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View model summary\n",
        "siamese_model.summary()"
      ],
      "metadata": {
        "id": "yip4XOiCKmXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Real Time Test**"
      ],
      "metadata": {
        "id": "5DSrTr_GJRsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.1 Verification Function**"
      ],
      "metadata": {
        "id": "coIlPzhLKyBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify(model, detection_threshold, verification_threshold):\n",
        "    # Build results array\n",
        "    results = []\n",
        "    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
        "        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n",
        "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
        "\n",
        "        # Make Predictions\n",
        "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
        "        results.append(result)\n",
        "\n",
        "    # Detection Threshold: Metric above which a prediciton is considered positive\n",
        "    detection = np.sum(np.array(results) > detection_threshold)\n",
        "\n",
        "    # Verification Threshold: Proportion of positive predictions / total positive samples\n",
        "    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images')))\n",
        "    verified = verification > verification_threshold\n",
        "\n",
        "    return results, verified"
      ],
      "metadata": {
        "id": "bT9MMLoVKy1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.2 OpenCV Real Time Verification**"
      ],
      "metadata": {
        "id": "LhhW03IgKyWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(4)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "\n",
        "    cv2.imshow('Verification', frame)\n",
        "\n",
        "    # Verification trigger\n",
        "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
        "        # Save input image to application_data/input_image folder\n",
        "        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
        "        # Run verification\n",
        "        results, verified = verify(siamese_model, 0.9, 0.7)\n",
        "        print(verified)\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "2b9qcFxFKzcP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}